{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['vhigh', 'vhigh.1', '2', '2.1', 'small', 'low', 'unacc'], dtype='object')\n",
      "Accuracy Results: {'Random Forest': 0.9855491329479769, 'Decision Tree': 0.9913294797687862, 'Logistic Regression': 0.6820809248554913, 'K-Nearest Neighbors': 0.930635838150289, 'Support Vector Machine': 0.930635838150289}\n",
      "Before Encoding Label Distribution:\n",
      " unacc\n",
      "2    1209\n",
      "0     384\n",
      "1      69\n",
      "3      65\n",
      "Name: count, dtype: int64\n",
      "After Encoding Label Distribution:\n",
      " unacc\n",
      "2    1209\n",
      "0     384\n",
      "1      69\n",
      "3      65\n",
      "Name: count, dtype: int64\n",
      "Confusion Matrices:\n",
      " {'Random Forest': array([[ 74,   1,   2,   0],\n",
      "       [  0,  14,   0,   0],\n",
      "       [  1,   0, 241,   0],\n",
      "       [  1,   0,   0,  12]]), 'Decision Tree': array([[ 76,   1,   0,   0],\n",
      "       [  0,  14,   0,   0],\n",
      "       [  1,   0, 241,   0],\n",
      "       [  1,   0,   0,  12]]), 'Logistic Regression': array([[  6,   0,  63,   8],\n",
      "       [  1,   0,  13,   0],\n",
      "       [ 13,   0, 228,   1],\n",
      "       [  3,   0,   8,   2]]), 'K-Nearest Neighbors': array([[ 66,   0,  11,   0],\n",
      "       [  7,   7,   0,   0],\n",
      "       [  1,   0, 241,   0],\n",
      "       [  3,   1,   1,   8]]), 'Support Vector Machine': array([[ 66,   1,   9,   1],\n",
      "       [ 10,   4,   0,   0],\n",
      "       [  0,   0, 242,   0],\n",
      "       [  3,   0,   0,  10]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xm/9m5jkr551jxg7scv_lxlytdm0000gn/T/ipykernel_58228/4022985235.py:17: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "file_path = \"car_evaluation.csv\"  # 로컬 파일 경로 지정\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.columns)\n",
    "\n",
    "# 결측치 확인 및 처리\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# 불필요한 컬럼 제거 (없음)\n",
    "\n",
    "# 엔코딩 (모든 컬럼을 숫자로 변환)\n",
    "label_encoders = {}\n",
    "for column in df.columns:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# 변환 전 레이블 분포\n",
    "before_encoding = df.iloc[:, -1].value_counts()\n",
    "\n",
    "# 데이터 분할\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 모델 리스트\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector Machine\": SVC()\n",
    "}\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "results = {}\n",
    "conf_matrices = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    results[name] = accuracy\n",
    "    conf_matrices[name] = conf_matrix\n",
    "\n",
    "# 변환 후 레이블 분포\n",
    "after_encoding = df.iloc[:, -1].value_counts()\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Accuracy Results:\", results)\n",
    "print(\"Before Encoding Label Distribution:\\n\", before_encoding)\n",
    "print(\"After Encoding Label Distribution:\\n\", after_encoding)\n",
    "print(\"Confusion Matrices:\\n\", conf_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE: 4.9603, R² Score: 0.5418\n",
      "Decision Tree - MSE: 6.6388, R² Score: 0.3867\n",
      "Random Forest - MSE: 3.7356, R² Score: 0.6549\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1️⃣ 데이터 로딩\n",
    "df = pd.read_csv(\"abalone.csv\")\n",
    "\n",
    "# 2️⃣ 데이터 전처리 (성별 Encoding)\n",
    "le = LabelEncoder()\n",
    "df['Sex'] = le.fit_transform(df['Sex'])\n",
    "\n",
    "# 3️⃣ 독립 변수(X)와 종속 변수(y) 설정\n",
    "X = df.drop(columns=['Rings'])  # 입력 데이터\n",
    "y = df['Rings']  # 예측할 타겟 값\n",
    "\n",
    "# 4️⃣ Train-Test 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5️⃣ 여러 회귀 모델 선언\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Support Vector Machine\": SVR(kernel='linear')\n",
    "}\n",
    "\n",
    "# 6️⃣ 모델 학습 & 평가\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # 모델 학습\n",
    "    y_pred = model.predict(X_test)  # 예측 수행\n",
    "    \n",
    "    # MSE 및 R² Score 계산\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{name} - MSE: {mse:.4f}, R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로딩\n",
    "df = pd.read_csv(\"abalone.csv\")\n",
    "\n",
    "# id는 학습에 불필요하므로 제거\n",
    "df = df.drop(columns=[\"id\"])\n",
    "\n",
    "# 입력 변수(X), 출력 변수(y)\n",
    "X = df.drop(columns=[\"Rings\"])\n",
    "y_reg = df[\"Rings\"]  # 회귀용 타겟\n",
    "\n",
    "# 분류용 타겟 만들기: Rings를 나이 범주로 나누기\n",
    "# 예: 0~7세: young, 8~10: middle, 11+: old\n",
    "def categorize_rings(rings):\n",
    "    if rings <= 7:\n",
    "        return 'young'\n",
    "    elif rings <= 10:\n",
    "        return 'middle'\n",
    "    else:\n",
    "        return 'old'\n",
    "\n",
    "y_clf = df[\"Rings\"].apply(categorize_rings)  # 분류용 타겟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 회귀 RMSE (Root Mean Squared Error): 2.2116130871218322\n"
     ]
    }
   ],
   "source": [
    "# 훈련/테스트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "# 전처리 + 선형 회귀 파이프라인\n",
    "regression_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", ColumnTransformer(transformers=[\n",
    "        (\"onehot\", OneHotEncoder(), [\"Sex\"])\n",
    "    ], remainder=\"passthrough\")),\n",
    "    (\"regressor\", LinearRegression())\n",
    "])\n",
    "\n",
    "# 학습\n",
    "regression_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred = regression_pipeline.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"✅ 회귀 RMSE (Root Mean Squared Error):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 분류 Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      middle       0.66      0.69      0.68       380\n",
      "         old       0.66      0.67      0.67       276\n",
      "       young       0.80      0.71      0.75       180\n",
      "\n",
      "    accuracy                           0.69       836\n",
      "   macro avg       0.71      0.69      0.70       836\n",
      "weighted avg       0.69      0.69      0.69       836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 훈련/테스트 분리\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X, y_clf, test_size=0.2, random_state=42)\n",
    "\n",
    "# 전처리 + 분류 파이프라인\n",
    "classification_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", ColumnTransformer(transformers=[\n",
    "        (\"onehot\", OneHotEncoder(), [\"Sex\"])\n",
    "    ], remainder=\"passthrough\")),\n",
    "    (\"classifier\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# 학습\n",
    "classification_pipeline.fit(X_train_c, y_train_c)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred_c = classification_pipeline.predict(X_test_c)\n",
    "print(\"✅ 분류 Classification Report:\\n\", classification_report(y_test_c, y_pred_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 로딩\n",
    "df = pd.read_csv(\"car_evaluation.csv\")\n",
    "\n",
    "# 컬럼 이름 정리\n",
    "df.columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "\n",
    "# 입력(X), 출력(y) 분리\n",
    "X = df.drop(columns=[\"class\"])\n",
    "y_clf = df[\"class\"]  # 분류용 라벨\n",
    "\n",
    "# 회귀용 타겟을 위해 class를 숫자로 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "y_reg = label_encoder.fit_transform(y_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 분류 결과:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.91      0.95      0.93        77\n",
      "        good       0.75      0.60      0.67        15\n",
      "       unacc       1.00      0.99      1.00       237\n",
      "       vgood       0.68      0.76      0.72        17\n",
      "\n",
      "    accuracy                           0.95       346\n",
      "   macro avg       0.84      0.83      0.83       346\n",
      "weighted avg       0.95      0.95      0.95       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 학습/테스트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_clf, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-hot 인코딩 + 랜덤 포레스트 파이프라인\n",
    "clf_pipeline = Pipeline(steps=[\n",
    "    (\"encoder\", ColumnTransformer([\n",
    "        (\"onehot\", OneHotEncoder(), X.columns)\n",
    "    ], remainder='passthrough')),\n",
    "    (\"classifier\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# 학습\n",
    "clf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred = clf_pipeline.predict(X_test)\n",
    "print(\"✅ 분류 결과:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 회귀 RMSE: 0.7719579196444836\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 학습/테스트 분리\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-hot + 선형 회귀 파이프라인\n",
    "reg_pipeline = Pipeline(steps=[\n",
    "    (\"encoder\", ColumnTransformer([\n",
    "        (\"onehot\", OneHotEncoder(), X.columns)\n",
    "    ], remainder='passthrough')),\n",
    "    (\"regressor\", LinearRegression())\n",
    "])\n",
    "\n",
    "# 학습\n",
    "reg_pipeline.fit(X_train_r, y_train_r)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred_r = reg_pipeline.predict(X_test_r)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_r, y_pred_r))\n",
    "print(\"✅ 회귀 RMSE:\", rmse)\n",
    "\n",
    "# 참고: 숫자 예측 결과를 다시 class로 디코딩하려면 아래처럼 가능\n",
    "decoded = label_encoder.inverse_transform(np.round(y_pred_r).astype(int))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
