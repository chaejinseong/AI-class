{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_invalid_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glucose 컬럼에서 0의 개수: 5\n",
      "BloodPressure 컬럼에서 0의 개수: 35\n",
      "SkinThickness 컬럼에서 0의 개수: 227\n",
      "Insulin 컬럼에서 0의 개수: 374\n",
      "BMI 컬럼에서 0의 개수: 11\n"
     ]
    }
   ],
   "source": [
    "for col in cols_with_invalid_zeros:\n",
    "    print(f\"{col} 컬럼에서 0의 개수: {(df[col] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for col in cols_with_invalid_zeros:\n",
    "    df[col] = df[col].replace(0, np.nan)  # 0을 NaN으로 바꿈\n",
    "    median = df[col].median()             # 중앙값 구함\n",
    "    df[col] = df[col].fillna(median)      # NaN을 중앙값으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# target은 제외하고 feature만\n",
    "X = df.drop('Outcome', axis=1)\n",
    "\n",
    "# 정규화\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639947</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>-0.031990</td>\n",
       "      <td>0.670643</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>0.166619</td>\n",
       "      <td>0.468492</td>\n",
       "      <td>1.425995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.205066</td>\n",
       "      <td>-0.528319</td>\n",
       "      <td>-0.012301</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>-0.852200</td>\n",
       "      <td>-0.365061</td>\n",
       "      <td>-0.190672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.233880</td>\n",
       "      <td>2.016662</td>\n",
       "      <td>-0.693761</td>\n",
       "      <td>-0.012301</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>-1.332500</td>\n",
       "      <td>0.604397</td>\n",
       "      <td>-0.105584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.073567</td>\n",
       "      <td>-0.528319</td>\n",
       "      <td>-0.695245</td>\n",
       "      <td>-0.540642</td>\n",
       "      <td>-0.633881</td>\n",
       "      <td>-0.920763</td>\n",
       "      <td>-1.041549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.141852</td>\n",
       "      <td>0.504422</td>\n",
       "      <td>-2.679076</td>\n",
       "      <td>0.670643</td>\n",
       "      <td>0.316566</td>\n",
       "      <td>1.549303</td>\n",
       "      <td>5.484909</td>\n",
       "      <td>-0.020496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0     0.639947  0.866045      -0.031990       0.670643 -0.181541  0.166619   \n",
       "1    -0.844885 -1.205066      -0.528319      -0.012301 -0.181541 -0.852200   \n",
       "2     1.233880  2.016662      -0.693761      -0.012301 -0.181541 -1.332500   \n",
       "3    -0.844885 -1.073567      -0.528319      -0.695245 -0.540642 -0.633881   \n",
       "4    -1.141852  0.504422      -2.679076       0.670643  0.316566  1.549303   \n",
       "\n",
       "   DiabetesPedigreeFunction       Age  \n",
       "0                  0.468492  1.425995  \n",
       "1                 -0.365061 -0.190672  \n",
       "2                  0.604397 -0.105584  \n",
       "3                 -0.920763 -1.041549  \n",
       "4                  5.484909 -0.020496  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 결측치 처리\n",
    "# 2. 정규화\n",
    "# 3. 분할\n",
    "\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y_class = df['Outcome']\n",
    "y_reg = df['Glucose']\n",
    "\n",
    "# 정규화\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 분류용 분할\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_scaled, y_class, test_size=0.2, random_state=42)\n",
    "\n",
    "# 회귀용 분할\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_scaled, y_reg, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x105a04fd0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/ai_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 1. 텐서로 변환\n",
    "X_train_tensor = torch.tensor(X_train_c, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_c.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_c, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_c.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# 2. DataLoader 생성\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 3. 모델 정의\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(8, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()  # 이진 분류용\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 4. 학습 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLPClassifier().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.6954\n",
      "Epoch 2/20, Loss: 0.6204\n",
      "Epoch 3/20, Loss: 0.5544\n",
      "Epoch 4/20, Loss: 0.4907\n",
      "Epoch 5/20, Loss: 0.4810\n",
      "Epoch 6/20, Loss: 0.4615\n",
      "Epoch 7/20, Loss: 0.4708\n",
      "Epoch 8/20, Loss: 0.4460\n",
      "Epoch 9/20, Loss: 0.4352\n",
      "Epoch 10/20, Loss: 0.4370\n",
      "Epoch 11/20, Loss: 0.4225\n",
      "Epoch 12/20, Loss: 0.4149\n",
      "Epoch 13/20, Loss: 0.4180\n",
      "Epoch 14/20, Loss: 0.4154\n",
      "Epoch 15/20, Loss: 0.4095\n",
      "Epoch 16/20, Loss: 0.4038\n",
      "Epoch 17/20, Loss: 0.4065\n",
      "Epoch 18/20, Loss: 0.3971\n",
      "Epoch 19/20, Loss: 0.4080\n",
      "Epoch 20/20, Loss: 0.3961\n"
     ]
    }
   ],
   "source": [
    "# 5. 학습 루프\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 75.97%\n"
     ]
    }
   ],
   "source": [
    "# 6. 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        predicted = (outputs.cpu().numpy() > 0.5).astype(int)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch.numpy()).sum()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀용 텐서 변환\n",
    "X_train_tensor = torch.tensor(X_train_r, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_r.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_r, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_r.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# DataLoader 구성\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMLPRegressor\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(MLPRegressor, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPRegressor, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(8, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)  # 활성화 함수 없음\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 장비 설정 및 학습 준비\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLPRegressor().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 15553.9887\n",
      "Epoch 2/20, Loss: 15352.6904\n",
      "Epoch 3/20, Loss: 15204.5962\n",
      "Epoch 4/20, Loss: 14469.6544\n",
      "Epoch 5/20, Loss: 13816.5209\n",
      "Epoch 6/20, Loss: 12414.0424\n",
      "Epoch 7/20, Loss: 10497.8493\n",
      "Epoch 8/20, Loss: 8437.0992\n",
      "Epoch 9/20, Loss: 6331.6344\n",
      "Epoch 10/20, Loss: 4272.0687\n",
      "Epoch 11/20, Loss: 2702.1924\n",
      "Epoch 12/20, Loss: 1776.6237\n",
      "Epoch 13/20, Loss: 1196.3055\n",
      "Epoch 14/20, Loss: 964.2556\n",
      "Epoch 15/20, Loss: 824.1014\n",
      "Epoch 16/20, Loss: 786.0971\n",
      "Epoch 17/20, Loss: 706.5546\n",
      "Epoch 18/20, Loss: 650.2680\n",
      "Epoch 19/20, Loss: 591.0960\n",
      "Epoch 20/20, Loss: 561.7494\n"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 24.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 평가\n",
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch).cpu().numpy()\n",
    "        predictions.extend(outputs)\n",
    "        actuals.extend(y_batch.numpy())\n",
    "\n",
    "# MSE 계산\n",
    "mse = mean_squared_error(actuals, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Test RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN 분류\n",
    "# 분류용 데이터\n",
    "X_train_tensor = torch.tensor(X_train_c, dtype=torch.float32).unsqueeze(1)  # (batch, 1, features)\n",
    "y_train_tensor = torch.tensor(y_train_c.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_c, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test_c.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Dataloader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 8, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNClassifier().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6198\n",
      "Epoch 2, Loss: 0.5412\n",
      "Epoch 3, Loss: 0.4784\n",
      "Epoch 4, Loss: 0.4506\n",
      "Epoch 5, Loss: 0.4372\n",
      "Epoch 6, Loss: 0.4500\n",
      "Epoch 7, Loss: 0.4163\n",
      "Epoch 8, Loss: 0.4380\n",
      "Epoch 9, Loss: 0.4156\n",
      "Epoch 10, Loss: 0.4392\n",
      "Epoch 11, Loss: 0.4104\n",
      "Epoch 12, Loss: 0.3985\n",
      "Epoch 13, Loss: 0.3958\n",
      "Epoch 14, Loss: 0.3964\n",
      "Epoch 15, Loss: 0.3989\n",
      "Epoch 16, Loss: 0.3954\n",
      "Epoch 17, Loss: 0.3803\n",
      "Epoch 18, Loss: 0.3861\n",
      "Epoch 19, Loss: 0.3825\n",
      "Epoch 20, Loss: 0.3902\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 74.68%\n"
     ]
    }
   ],
   "source": [
    "# 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch).cpu().numpy()\n",
    "        predicted = (outputs > 0.5).astype(int)\n",
    "        correct += (predicted == y_batch.numpy()).sum()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 텐서 변환 + CNN용 형태 (unsqueeze)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mtensor(X_train_r, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (batch, 1, features)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m y_train_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_train_r\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m X_test_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_test_r, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# 텐서 변환 + CNN용 형태 (unsqueeze)\n",
    "X_train_tensor = torch.tensor(X_train_r, dtype=torch.float32).unsqueeze(1)  # (batch, 1, features)\n",
    "y_train_tensor = torch.tensor(y_train_r.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_r, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test_r.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# DataLoader 생성\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNRegressor, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 8, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # 활성화 함수 없음 (회귀)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNRegressor().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 15477.7448\n",
      "Epoch 2, Loss: 13876.1903\n",
      "Epoch 3, Loss: 8537.9873\n",
      "Epoch 4, Loss: 2602.8234\n",
      "Epoch 5, Loss: 1565.0324\n",
      "Epoch 6, Loss: 1233.8521\n",
      "Epoch 7, Loss: 1086.4831\n",
      "Epoch 8, Loss: 1023.5634\n",
      "Epoch 9, Loss: 933.7635\n",
      "Epoch 10, Loss: 860.8677\n",
      "Epoch 11, Loss: 780.2200\n",
      "Epoch 12, Loss: 718.4413\n",
      "Epoch 13, Loss: 662.6441\n",
      "Epoch 14, Loss: 643.8965\n",
      "Epoch 15, Loss: 536.3581\n",
      "Epoch 16, Loss: 500.8459\n",
      "Epoch 17, Loss: 448.9327\n",
      "Epoch 18, Loss: 392.8699\n",
      "Epoch 19, Loss: 359.0199\n",
      "Epoch 20, Loss: 313.8256\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m actuals \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# import numpy as np\n",
    "\n",
    "# model.eval()\n",
    "# predictions = []\n",
    "# actuals = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for X_batch, y_batch in test_loader:\n",
    "#         X_batch = X_batch.to(device)\n",
    "#         outputs = model(X_batch).cpu().numpy()\n",
    "#         predictions.extend(outputs)\n",
    "#         actuals.extend(y_batch.numpy())\n",
    "\n",
    "# mse = mean_squared_error(actuals, predictions)\n",
    "# rmse = np.sqrt(mse)\n",
    "# print(f\"Test RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)))\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x))\n\u001b[0;32m---> 18\u001b[0m model_c2 \u001b[38;5;241m=\u001b[39m DiabetesClassifier(\u001b[43mX_train_c\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     19\u001b[0m criterion_c2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[1;32m     20\u001b[0m optimizer_c2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model_c2\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_c' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DiabetesClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        return self.sigmoid(self.fc3(x))\n",
    "\n",
    "model_c2 = DiabetesClassifier(X_train_c.shape[1])\n",
    "criterion_c2 = nn.BCELoss()\n",
    "optimizer_c2 = torch.optim.Adam(model_c2.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(50):\n",
    "    model_c2.train()\n",
    "    optimizer_c2.zero_grad()\n",
    "    output = model_c2(X_train_c_tensor)\n",
    "    loss = criterion_c2(output, y_train_c_tensor)\n",
    "    loss.backward()\n",
    "    optimizer_c2.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 컬럼 목록:\n",
      "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
      "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
      "      dtype='object')\n",
      "\n",
      "📌 결측치 유무 확인:\n",
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64\n",
      "\n",
      "📌 요약 통계:\n",
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
      "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
      "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
      "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
      "\n",
      "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
      "count  768.000000                768.000000  768.000000  768.000000  \n",
      "mean    31.992578                  0.471876   33.240885    0.348958  \n",
      "std      7.884160                  0.331329   11.760232    0.476951  \n",
      "min      0.000000                  0.078000   21.000000    0.000000  \n",
      "25%     27.300000                  0.243750   24.000000    0.000000  \n",
      "50%     32.000000                  0.372500   29.000000    0.000000  \n",
      "75%     36.600000                  0.626250   41.000000    1.000000  \n",
      "max     67.100000                  2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "# 데이터 구조 확인\n",
    "print(\"📌 컬럼 목록:\")\n",
    "print(df.columns)\n",
    "\n",
    "print(\"\\n📌 결측치 유무 확인:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n📌 요약 통계:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Glucose  BloodPressure  SkinThickness     Insulin         BMI\n",
      "count  768.000000     768.000000     768.000000  768.000000  768.000000\n",
      "mean   121.656250      72.386719      29.108073  140.671875   32.455208\n",
      "std     30.438286      12.096642       8.791221   86.383060    6.875177\n",
      "min     44.000000      24.000000       7.000000   14.000000   18.200000\n",
      "25%     99.750000      64.000000      25.000000  121.500000   27.500000\n",
      "50%    117.000000      72.000000      29.000000  125.000000   32.300000\n",
      "75%    140.250000      80.000000      32.000000  127.250000   36.600000\n",
      "max    199.000000     122.000000      99.000000  846.000000   67.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xm/9m5jkr551jxg7scv_lxlytdm0000gn/T/ipykernel_57713/2127489170.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/xm/9m5jkr551jxg7scv_lxlytdm0000gn/T/ipykernel_57713/2127489170.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/xm/9m5jkr551jxg7scv_lxlytdm0000gn/T/ipykernel_57713/2127489170.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/xm/9m5jkr551jxg7scv_lxlytdm0000gn/T/ipykernel_57713/2127489170.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/xm/9m5jkr551jxg7scv_lxlytdm0000gn/T/ipykernel_57713/2127489170.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 0을 결측치로 변환할 컬럼 목록\n",
    "cols_with_zero_as_null = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "\n",
    "# 0을 NaN으로 바꾸고 중앙값으로 대체\n",
    "for col in cols_with_zero_as_null:\n",
    "    df[col] = df[col].replace(0, np.nan)\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# 처리 결과 확인\n",
    "print(df[cols_with_zero_as_null].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 입력 피처(X), 분류용 타겟(y_class), 회귀용 타겟(y_reg)\n",
    "X = df.drop(columns=['Outcome', 'Glucose'])  # Glucose는 회귀 타겟으로 따로 사용\n",
    "y_class = df['Outcome']                      # 분류용\n",
    "y_reg = df['Glucose']                        # 회귀용\n",
    "\n",
    "# 정규화\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# 분류용 데이터셋 분할\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_scaled, y_class, test_size=0.2, random_state=42)\n",
    "\n",
    "# 회귀용 데이터셋 분할\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_scaled, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "# 분류용 텐서 변환\n",
    "X_train_c_tensor = torch.tensor(X_train_c, dtype=torch.float32)\n",
    "y_train_c_tensor = torch.tensor(y_train_c.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_c_tensor = torch.tensor(X_test_c, dtype=torch.float32)\n",
    "y_test_c_tensor = torch.tensor(y_test_c.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# 회귀용 텐서 변환\n",
    "X_train_r_tensor = torch.tensor(X_train_r, dtype=torch.float32)\n",
    "y_train_r_tensor = torch.tensor(y_train_r.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_r_tensor = torch.tensor(X_test_r, dtype=torch.float32)\n",
    "y_test_r_tensor = torch.tensor(y_test_r.values, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.6590\n",
      "Epoch 20, Loss: 0.6257\n",
      "Epoch 30, Loss: 0.5953\n",
      "Epoch 40, Loss: 0.5632\n",
      "Epoch 50, Loss: 0.5404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.84      0.78        99\n",
      "         1.0       0.60      0.44      0.51        55\n",
      "\n",
      "    accuracy                           0.69       154\n",
      "   macro avg       0.66      0.64      0.64       154\n",
      "weighted avg       0.68      0.69      0.68       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 분류 딥러닝 모델 정의 (클래스 기반, Dropout 포함)\n",
    "class DiabetesClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        return self.sigmoid(self.output(x))\n",
    "\n",
    "# 모델 생성 및 학습 준비\n",
    "model_c2 = DiabetesClassifier(X_train_c_tensor.shape[1])\n",
    "criterion_c2 = nn.BCELoss()\n",
    "optimizer_c2 = torch.optim.Adam(model_c2.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(50):\n",
    "    model_c2.train()\n",
    "    optimizer_c2.zero_grad()\n",
    "    output = model_c2(X_train_c_tensor)\n",
    "    loss = criterion_c2(output, y_train_c_tensor)\n",
    "    loss.backward()\n",
    "    optimizer_c2.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 평가\n",
    "model_c2.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model_c2(X_test_c_tensor)\n",
    "    preds_cls = (preds > 0.5).float()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_c_tensor, preds_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 회귀 모델 정의\n",
    "class GlucoseRegressor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.output = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(torch.relu(self.fc3(x)))\n",
    "        return self.output(x)  # 회귀이므로 시그모이드 안 씀\n",
    "\n",
    "# 모델 정의\n",
    "model_r2 = GlucoseRegressor(X_train_r_tensor.shape[1])\n",
    "criterion_r2 = nn.MSELoss()\n",
    "optimizer_r2 = torch.optim.Adam(model_r2.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(50):\n",
    "    model_r2.train()\n",
    "    optimizer_r2.zero_grad()\n",
    "    output = model_r2(X_train_r_tensor)\n",
    "    loss = criterion_r2(output, y_train_r_tensor)\n",
    "    loss.backward()\n",
    "    optimizer_r2.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 평가\n",
    "model_r2.eval()\n",
    "with torch.no_grad():\n",
    "    preds_r = model_r2(X_test_r_tensor)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print(\"MSE:\", mean_squared_error(y_test_r_tensor, preds_r))\n",
    "print(\"R2 Score:\", r2_score(y_test_r_tensor, preds_r))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
